В науке о данных самое важное применение регрессии состоит в предсказании зависимой переменной (исхода). В некоторых случаях, однако, получение более глубокого представления непосредственно из самого уравнения, чтобы понять природу связи между предсказателями и исходом, является ценностью. В данном разделе приводятся рекомендации по обследованию уравнения регрессии и его интерпретированию.

**Ключевые термины для интерпретирования уравнения регрессии:**

* **Коррелированные переменные (correlated variables)** - когда предсказательные переменные высоко коррелированы, сложно интерпретировать отдельные коэффициенты.
* **Мультиколлинеарность (multicollinearity)** - когда предсказательные переменные имеют идеальную или почти идеальную корреляцию, регрессия может быть нестабильной либо ее невозможно вычислить.
* **Искажающие переменные (confounding variables)** - важный предсказатель, которые, если его опустить, приводит к мнимым связям в уравнении регрессии.
* **Главные эффекты (main effects)** - связь между предсказательной переменной и переменной исхода, которая не зависит от других переменных.
* **Взаимодействия (interactions)** - взаимозависимая связь между двумя или несколькими предсказателями и исходом.

### Коррелированные предсказатели

Наличие коррелированных предсказателей усложняет интерпретирование знака и значение регрессионных коэффициентов (и может раздуть стандартную ошибку оценочных значений). Например, коэффициент для спален при продаже дома может быть отрицательным, как такое возможно? Это вызвано тем, что предсказательные переменные коррелированы: в более крупных домах наблюдается тенденция к большему количеству спален, и именно размер дома управляет его стоимостью, а не число спален.

### Мультиколлинеарность

Предельный случай коррелированных переменных производит мульиколлинеарность - условие, в котором существует избыток среди предсказательным переменных. Идеальная мультиколлинеарность случается, когда одна предсказательная переменная может быть выражена как линейная комбинация других. Мультиколлинеарность происходит когда:

* переменная включается в состав модели многократно по ошибке;
* из факторной переменной создаются $P$ фиктивных переменных вместо $P-1$
* две переменные почти идеально коррелированы друг с другом.

Вопрос мультиколлинеарности в регрессии должен быть решен - переменные необходимо исключать до тех пор, пока мультиколлинеарность не исчезнет. Регрессия не имеет хорошо определенного в присутствии идеальной мультиколлинеарности.  В случае неидеальной мультиколлинеарности вычислительная система может получить решение, но результаты могут быть нестабильными.

### Искажающие переменные

С коррелированными переменными проблема состоит во включении переменных в состав: включение разных переменных, которые имеют похожую предсказательную связь с откликом. С *искажающими переменными* проблемой является исключение переменных из состава: важная переменная не включена в уравнение регрессии. Наивная интерпретация коэффициентов уравнения может привести к несостоятельным заключениям.

### Взаимодействия и главные эффекты

Специалисты-статистики предпочитают проводить различие между *главными эффектами*, или независимыми переменными, и взаимодействиями между главными эффектами. *Главные эффект* - это то, подразумевается под *предсказательными переменными* в уравнении регрессии. Неявное допущение, когда в модели используются только главные эффекты, состоит в том, что связь между предсказательной переменной и откликом не зависит от других предсказательных переменных. Зачастую это не так.

Например, местоположение в торговле недвижимостью - краеугольный камень, и естественно допустить, что связь между, скажем размером дома и продажной ценой зависит от местоположения. Большой дом, построенный в районе с низкой арендной платой, не будет сохранять одинаковую стоимость, что и большой дом, построенный в дорогом районе.

**Ключевые идеи для интерпретирования уравнения регрессии:**

* Вследствие корреляции между предсказателями необходимо проявлять осторожность в интепретации коэффициентов в множественной линейной регрессии.
* Мультиколлинеарность может вызывать числовую нестабильность в подгонке уравнения регрессии.
* Искажающая переменная является важным предсказателем, который не учтен в модели и может привести к уравнению регрессии с мнимыми связями.
* Член уравнения, характеризующий взаимодействие между двумя переменными, необходим, если связь между переменными и откликом является взаимозависимой.