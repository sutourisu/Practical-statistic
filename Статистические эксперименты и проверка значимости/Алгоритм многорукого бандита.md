Многорукие бандиты предлагают подход к тестированию, в особенности веб-тестированию, который позволяет выполнять явную оптимизацию и принимать более скорые решения, чем традиционный статистический подход к планированию экспериментов.

**Ключевые термины для алгоритма многорукого бандита:**

* **Многорукий бандинт (multi-arm bandit)** - воображаемый игровой автомат с несколькими пусковыми рычагами, или ручками, на которые игрок может нажимать по выбору, при этом каждая рука имеет разный выигрыш; здесь взят как аналогия многовариантного эксперимента.
* **Рычаг (arm)** - вариант в эксперименте (например, "заголовок A в веб-тесте").
* **Выигрыш (win)** - экспериментальный аналог выигрыша в автомате (например, "клиент щелкает на ссылку").

Традиционный A/B-тест предусматривает, что данные, собранные в эксперименте в соответствии с детальным планом, отвечают на конкретно поставленный вопрос: что лучше - вариант A или вариант B? Изначально предполагается, что как только мы получаем ответ на этот вопрос, экспериментирование заканчивается, и мы переходим к действиям по его результатам.

Бандитские алгоритмы очень популярные в веб-тестировании, позволяют тестировать несколько вариантов одним махом и делать выводы быстрее, чем традиционные статистические планы экспериментов.

Предположим, что каждый "выигрыш" приносит одинаковую сумму, независимо от того, за какой рычаг вы потянули. Отличается только вероятность выигрыша. Далее, допустим, что сначала вы пробуете каждый рычаг по 50 раз и получаете следующие результаты:

* рычаг A: 10 выигрышей из 50;
* рычаг B: 2 выигрыша из 50;
* рычаг C: 4 выигрыша из 50;

Один из предельных подходов состоит в том, чтобы сказать: "Похоже, рычаг A приносит выигрыш - надо прекратить попытки и остановиться на A". Этот шаг в полной мере пользуется информацией начального испытания. Если А действительно превосходит, то мы извлекаем из этого выгоду с самого начала. С другой стороны, если B или C реально лучше, то мы теряем любую возможность это обнаружить.

Другой предельный подход состоит в том, чтобы сказать: "Сдается, что все это во власти случая, - попробую понажимать их одинаково". Это дает максимальную возможность проявиться другим альтернативам помимо А. Однако по ходу мы задействуем варианты, которые выглядят менее успешными. Сколько времени мы позволим этому продолжаться? Бандинтские алгоритмы действуют в соответствии с гибридным подходом: мы чаще начинаем нажимать на рычаг A, пользуясь его очевидным превосходством, но мы не отказываемся от B и C. Мы просто обращаемся к ним не так часто. Если A продолжает превосходить, то мы продолжаем смещать ресурсы, отдаляясь от B и C и чаще нажимая на А. Если с другой стороны C начинает работать лучше, а A - хуже, то мы можем сместиться от A назад к С. Если окажется, что один из них превосходит A и это было скрыто в начальном испытании в силу случайности, то теперь он имеет возможность проявить себя при дальнейшем тестировании.

Вот один из простых алгоритмов, эпсилон-жадный алгоритм для A/B-теста:

1. Сгенерировать равномерное распределенное случайное число в интервале между 0 и 1
2. Если число находится между 0 и эпсилон (где эпсилон - это число между 0 и 1), подбросить справедливую монету и:
	* если монета повернется орлом, то предложить вариант А;
	* если монета повернется решкой, то предложить вариант B;
3. Если число больше или равно $\epsilon$, то показать любое предложение, которое до настоящего времени имело самую высокую интенсивность откликов.

Эпсилон - единственный параметр, который управляет указанным алгоритмом. Если эпсилон равен 1, то мы заканчиваем стандартным простым A/B-тестом (случайное размещение между A и B для каждого испытуемого). Если эпсилон равен 0, то мы заканчивает чисто жадным алгоритмом - он не стремится продолжать экспериментироать, просто относя испытуемых (посетителей веб-сайта) к наиболее превосходящему варианту.

Более сложный алгоритм использует "отбор по методу Томпсона". Данная процедура "извлекает выборки" на каждом этапе, максимизируя вероятность выбора наилучшего рычага. Разумеется, вы не знаете, какой рычаг является лучшим, но по мере того, как вы наблюдаете за выплатой при каждом последующем извлечении, вы получаете все больше информации.

**Ключевые идеи для алгоритма многорукого бандита:**

* Традиционные A/B-тесты предусматривают процесс случайного отбора, который может привести к чрезмерному показу варианта худшего по качеству.
* Многорукие бандиты, напротив, изменяют процесс отбора, инкорпорируя информацию, усваиваемую во время эксперимента, и уменьшают частоту показа менее качественного варианта.
* Они также упрощают эффективную обработку более двух вариантов.
* Существуют разные алгоритмы, которые смещают вероятность отбора от менее качественного варианта к более качественному.
